{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65773410-2726-4dc9-b0f2-664a2a544227",
   "metadata": {},
   "source": [
    "## Find High Demand Centres across India ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e3260c2-506a-477d-9035-9ced739836ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Chocolate Demand Centres (CDP score, higher = stronger potential):\n",
      " rank           city demand_score\n",
      "    1    Delhi (NCR)       1.0000\n",
      "    2   Mumbai (MMR)       0.7480\n",
      "    3      Bengaluru       0.6262\n",
      "    4      Hyderabad       0.5875\n",
      "    5        Chennai       0.5705\n",
      "    6        Kolkata       0.5364\n",
      "    7      Ahmedabad       0.4896\n",
      "    8          Surat       0.4329\n",
      "    9 Pune (PCMC UA)       0.4185\n",
      "   10         Jaipur       0.2310\n",
      "   11         Nagpur       0.1916\n",
      "   12        Lucknow       0.1835\n",
      "   13         Indore       0.1670\n",
      "   14     Coimbatore       0.1615\n",
      "   15         Kanpur       0.1575\n",
      "   16          Patna       0.1031\n",
      "   17         Bhopal       0.0986\n",
      "   18       Vadodara       0.0977\n",
      "   19  Visakhapatnam       0.0950\n",
      "   20          Kochi       0.0000\n",
      "\n",
      "Step-by-step calculation: Mumbai (MMR)\n",
      "  Population (agglomeration, 2025): 27,600,000\n",
      "  ln(pop)_city = 17.1333, ln(pop)_min = 14.3223, ln(pop)_max = 17.3907\n",
      "  PopIdx = (ln(pop)_city - ln_min) / (ln_max - ln_min) = 0.9161\n",
      "  NSDP_pc (₹): 309,340  [min=68,828, max=513,131]\n",
      "  AffluenceIdx = (NSDP - min) / (max - min) = 0.5413\n",
      "  Quick-commerce flags: Blinkit=1, Instamart=1, Zepto=1  ⇒ QCAS=1.00\n",
      "  TC = PopIdx * (0.6 + 0.4*AffIdx) = 0.7480\n",
      "  MC = PopIdx * (0.4*AffIdx + 0.6*QCAS) = 0.7480\n",
      "  FINAL CDP = 0.75*TC + 0.25*MC = 0.7480\n",
      "\n",
      "Step-by-step calculation: Delhi (NCR)\n",
      "  Population (agglomeration, 2025): 35,700,000\n",
      "  ln(pop)_city = 17.3907, ln(pop)_min = 14.3223, ln(pop)_max = 17.3907\n",
      "  PopIdx = (ln(pop)_city - ln_min) / (ln_max - ln_min) = 1.0000\n",
      "  NSDP_pc (₹): 513,131  [min=68,828, max=513,131]\n",
      "  AffluenceIdx = (NSDP - min) / (max - min) = 1.0000\n",
      "  Quick-commerce flags: Blinkit=1, Instamart=1, Zepto=1  ⇒ QCAS=1.00\n",
      "  TC = PopIdx * (0.6 + 0.4*AffIdx) = 1.0000\n",
      "  MC = PopIdx * (0.4*AffIdx + 0.6*QCAS) = 1.0000\n",
      "  FINAL CDP = 0.75*TC + 0.25*MC = 1.0000\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Chocolate Demand Potential (CDP) – India Urban Centers (2025)\n",
    "\n",
    "WHAT THIS DOES\n",
    "--------------\n",
    "1) Builds a comparable demand score for major Indian urban centers.\n",
    "2) Ranks the Top 20 cities and saves a full table to CSV and Excel.\n",
    "\n",
    "METHOD (transparent)\n",
    "--------------------\n",
    "Inputs:\n",
    "  A) Urban agglomeration population (2025) – constants included below (CityPopulation; a few cross-checked via Macrotrends/WorldPopulationReview).\n",
    "  B) State/UT affluence proxy = per-capita NSDP (₹) FY 2024–25 (MOSPI table mirrored on Wikipedia).\n",
    "  C) Quick-commerce presence flags: Blinkit / Swiggy Instamart / Zepto (presence=1, absence=0).\n",
    "\n",
    "Indices:\n",
    "  PopIdx_i = (ln(Pop_i) - min ln(Pop)) / (max ln(Pop) - min ln(Pop))       # dampens mega-city dominance\n",
    "  AffIdx_i = (NSDP_i - min NSDP) / (max NSDP - min NSDP)\n",
    "  QCAS_i   = (1{Blinkit} + 1{Instamart} + 1{Zepto}) / 3\n",
    "\n",
    "Components:\n",
    "  TC_i = PopIdx_i * (0.6 + 0.4 * AffIdx_i)                                 # traditional-led\n",
    "  MC_i = PopIdx_i * (0.4 * AffIdx_i + 0.6 * QCAS_i)                        # modern/q-commerce led\n",
    "\n",
    "FINAL SCORE honoring traditional trade ≈ 75%:\n",
    "  CDP_i = 0.75*TC_i + 0.25*MC_i\n",
    "\n",
    "ASSUMPTIONS\n",
    "-----------\n",
    "- You requested traditional trade ~75% ⇒ weighted as above.\n",
    "- Affluence proxied by state/UT per-capita NSDP (₹) FY 2024–25.\n",
    "- Q-commerce presence: Blinkit/Instamart widely present in big cities; Zepto present in top metros.\n",
    "  Adjust flags easily below if you have more precise coverage for 2025.\n",
    "- Populations are agglomerations (not municipal-only) to compare like-with-like.\n",
    "\n",
    "SOURCES (to be cited in your deck)\n",
    "----------------------------------\n",
    "- City populations: CityPopulation’s Major Agglomerations list (2025-01-01).\n",
    "- Affluence: MOSPI per-capita Net State Domestic Product FY 2024–25 (table mirrored on Wikipedia).\n",
    "- Q-commerce footprints: Blinkit city list; Swiggy Instamart (~100 cities by Mar-2025); Zepto (30+ cities by 2024/25).\n",
    "  (All inputs baked into code for offline reproducibility.)\n",
    "\n",
    "OUTPUTS\n",
    "-------\n",
    "- ./chocolate_demand_index_2025.csv\n",
    "- ./chocolate_demand_index_2025.xlsx  (sheet: CDP_2025)\n",
    "\n",
    "USAGE\n",
    "-----\n",
    "python chocolate_demand_centers.py\n",
    "\n",
    "Optionally edit CITIES, STATE_NSDP_2024_25, and QCOV flags for your latest info.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from math import log\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# 1) INPUTS (edit-friendly)\n",
    "# ----------------------------\n",
    "\n",
    "@dataclass\n",
    "class City:\n",
    "    name: str\n",
    "    state: str\n",
    "    population_2025: int           # urban agglomeration population\n",
    "    pop_source: str                # short note for provenance\n",
    "    blinkit: int                   # 1 if present, 0 if not\n",
    "    instamart: int                 # 1 if present, 0 if not\n",
    "    zepto: int                     # 1 if present, 0 if not\n",
    "\n",
    "# Agglomeration populations (2025). Sources noted; adjust as needed.\n",
    "CITIES: List[City] = [\n",
    "    City(\"Delhi (NCR)\",         \"Delhi\",         35700000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Mumbai (MMR)\",        \"Maharashtra\",   27600000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Bengaluru\",           \"Karnataka\",     14700000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Hyderabad\",           \"Telangana\",     11700000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Chennai\",             \"Tamil Nadu\",    12900000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Kolkata\",             \"West Bengal\",   17900000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Ahmedabad\",           \"Gujarat\",        9900000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Surat\",               \"Gujarat\",        8050000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Pune (PCMC UA)\",      \"Maharashtra\",    8000000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Jaipur\",              \"Rajasthan\",      4525000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Lucknow\",             \"Uttar Pradesh\",  4225000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "    City(\"Kanpur\",              \"Uttar Pradesh\",  3700000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "    City(\"Indore\",              \"Madhya Pradesh\", 3750000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "    City(\"Nagpur\",              \"Maharashtra\",    3575000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "    City(\"Coimbatore\",          \"Tamil Nadu\",     3075000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "    City(\"Patna\",               \"Bihar\",          2950000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "    City(\"Bhopal\",              \"Madhya Pradesh\", 2686000, \"Macrotrends/WPR 2025 metro\",         1, 1, 0),\n",
    "    City(\"Vadodara\",            \"Gujarat\",        2425000, \"Macrotrends/WPR 2025 metro\",         1, 1, 0),\n",
    "    City(\"Visakhapatnam\",       \"Andhra Pradesh\", 2440000, \"Macrotrends/WPR 2025 metro\",         1, 1, 0),\n",
    "    City(\"Kochi\",               \"Kerala\",         1660000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "]\n",
    "\n",
    "# State/UT per-capita NSDP (₹) – FY 2024–25 (current prices). Source: MOSPI (table mirrored on Wikipedia).\n",
    "STATE_NSDP_2024_25: Dict[str, int] = {\n",
    "    \"Delhi\":          513_131,\n",
    "    \"Maharashtra\":    309_340,\n",
    "    \"Karnataka\":      380_906,\n",
    "    \"Telangana\":      427_730,\n",
    "    \"Tamil Nadu\":     350_695,\n",
    "    \"West Bengal\":    171_184,\n",
    "    \"Gujarat\":        336_875,\n",
    "    \"Rajasthan\":      187_454,\n",
    "    \"Uttar Pradesh\":  127_468,\n",
    "    \"Madhya Pradesh\": 156_381,\n",
    "    \"Bihar\":           68_828,\n",
    "    \"Kerala\":         317_723,\n",
    "    \"Andhra Pradesh\": 298_058,\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# 2) HELPER FUNCTIONS\n",
    "# ----------------------------\n",
    "\n",
    "def normalize_log_pop(values: pd.Series) -> pd.Series:\n",
    "    \"\"\"Log-scale population then min-max normalize to [0,1].\"\"\"\n",
    "    ln_vals = np.log(values.astype(float))\n",
    "    return (ln_vals - ln_vals.min()) / (ln_vals.max() - ln_vals.min())\n",
    "\n",
    "def normalize_minmax(values: pd.Series) -> pd.Series:\n",
    "    \"\"\"Standard min-max normalization to [0,1].\"\"\"\n",
    "    vals = values.astype(float)\n",
    "    return (vals - vals.min()) / (vals.max() - vals.min())\n",
    "\n",
    "def compute_scores(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Compute PopIdx, AffluenceIdx, QCAS, TC, MC, and final CDP score.\"\"\"\n",
    "    # Population index\n",
    "    df[\"pop_index\"] = normalize_log_pop(df[\"population_2025\"])\n",
    "    # Affluence index (via state/UT NSDP)\n",
    "    df[\"nsdp_pc_2024_25\"] = df[\"state\"].map(STATE_NSDP_2024_25)\n",
    "    if df[\"nsdp_pc_2024_25\"].isna().any():\n",
    "        # if any states missing in dict, fill with series median\n",
    "        df[\"nsdp_pc_2024_25\"] = df[\"nsdp_pc_2024_25\"].fillna(df[\"nsdp_pc_2024_25\"].median())\n",
    "    df[\"affluence_index\"] = normalize_minmax(df[\"nsdp_pc_2024_25\"])\n",
    "\n",
    "    # Quick-commerce availability score\n",
    "    df[\"qcas\"] = (df[\"blinkit\"] + df[\"instamart\"] + df[\"zepto\"]) / 3.0\n",
    "\n",
    "    # Components (see method)\n",
    "    df[\"TC\"] = df[\"pop_index\"] * (0.6 + 0.4 * df[\"affluence_index\"])\n",
    "    df[\"MC\"] = df[\"pop_index\"] * (0.4 * df[\"affluence_index\"] + 0.6 * df[\"qcas\"])\n",
    "\n",
    "    # Final score with 75% traditional weight\n",
    "    df[\"demand_score\"] = 0.75*df[\"TC\"] + 0.25*df[\"MC\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "def explain_city(df: pd.DataFrame, city_name: str) -> None:\n",
    "    \"\"\"Prints step-by-step calculation for a given city.\"\"\"\n",
    "    if city_name not in set(df[\"city\"]):\n",
    "        print(f\"[warn] '{city_name}' not found in dataset.\")\n",
    "        return\n",
    "\n",
    "    # For transparency, recompute the exact normalized elements\n",
    "    pop_series = df[\"population_2025\"].astype(float)\n",
    "    ln_pop    = np.log(pop_series)\n",
    "    ln_min, ln_max = ln_pop.min(), ln_pop.max()\n",
    "\n",
    "    row = df.loc[df[\"city\"] == city_name].iloc[0]\n",
    "    ln_city = log(float(row[\"population_2025\"]))\n",
    "\n",
    "    nsdp_min = df[\"nsdp_pc_2024_25\"].min()\n",
    "    nsdp_max = df[\"nsdp_pc_2024_25\"].max()\n",
    "\n",
    "    pop_idx = (ln_city - ln_min) / (ln_max - ln_min)\n",
    "    aff_idx = (row[\"nsdp_pc_2024_25\"] - nsdp_min) / (nsdp_max - nsdp_min)\n",
    "    qcas    = (row[\"blinkit\"] + row[\"instamart\"] + row[\"zepto\"]) / 3.0\n",
    "\n",
    "    TC = pop_idx * (0.6 + 0.4*aff_idx)\n",
    "    MC = pop_idx * (0.4*aff_idx + 0.6*qcas)\n",
    "    CDP = 0.75*TC + 0.25*MC\n",
    "\n",
    "    print(f\"\\nStep-by-step calculation: {row['city']}\")\n",
    "    print(f\"  Population (agglomeration, 2025): {int(row['population_2025']):,}\")\n",
    "    print(f\"  ln(pop)_city = {ln_city:.4f}, ln(pop)_min = {ln_min:.4f}, ln(pop)_max = {ln_max:.4f}\")\n",
    "    print(f\"  PopIdx = (ln(pop)_city - ln_min) / (ln_max - ln_min) = {pop_idx:.4f}\")\n",
    "    print(f\"  NSDP_pc (₹): {int(row['nsdp_pc_2024_25']):,}  [min={int(nsdp_min):,}, max={int(nsdp_max):,}]\")\n",
    "    print(f\"  AffluenceIdx = (NSDP - min) / (max - min) = {aff_idx:.4f}\")\n",
    "    print(f\"  Quick-commerce flags: Blinkit={row['blinkit']}, Instamart={row['instamart']}, Zepto={row['zepto']}  ⇒ QCAS={qcas:.2f}\")\n",
    "    print(f\"  TC = PopIdx * (0.6 + 0.4*AffIdx) = {TC:.4f}\")\n",
    "    print(f\"  MC = PopIdx * (0.4*AffIdx + 0.6*QCAS) = {MC:.4f}\")\n",
    "    print(f\"  FINAL CDP = 0.75*TC + 0.25*MC = {CDP:.4f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3) BUILD DATAFRAME & SCORE\n",
    "# ----------------------------\n",
    "\n",
    "def build_dataframe(cities: List[City]) -> pd.DataFrame:\n",
    "    df = pd.DataFrame([asdict(c) for c in cities])\n",
    "    df.rename(columns={\n",
    "        \"name\": \"city\",\n",
    "    }, inplace=True)\n",
    "    df = compute_scores(df)\n",
    "    return df\n",
    "\n",
    "# ----------------------------\n",
    "# 4) MAIN\n",
    "# ----------------------------\n",
    "\n",
    "def main():\n",
    "    df = build_dataframe(CITIES)\n",
    "\n",
    "    # Sort by demand score and select top 20\n",
    "    df_sorted = df.sort_values(\"demand_score\", ascending=False).reset_index(drop=True)\n",
    "    top20 = df_sorted.head(20).copy()\n",
    "    top20[\"rank\"] = range(1, len(top20)+1)\n",
    "\n",
    "    # Reorder columns for readability\n",
    "    cols = [\n",
    "        \"rank\",\"city\",\"state\",\"population_2025\",\"nsdp_pc_2024_25\",\n",
    "        \"pop_index\",\"affluence_index\",\"qcas\",\"TC\",\"MC\",\"demand_score\",\"pop_source\"\n",
    "    ]\n",
    "    top20 = top20[cols]\n",
    "\n",
    "    # Print to console\n",
    "    print(\"\\nTop 20 Chocolate Demand Centres (CDP score, higher = stronger potential):\")\n",
    "    print(top20[[\"rank\",\"city\",\"demand_score\"]].to_string(index=False, formatters={\"demand_score\": \"{:.4f}\".format}))\n",
    "\n",
    "    # Save files\n",
    "    out_csv  = Path(\"chocolate_demand_index_2025_python.csv\")\n",
    "    out_xlsx = Path(\"chocolate_demand_index_2025_python.xlsx\")\n",
    "    df_sorted[cols[1:]]  # ensure we can export complete dataset if needed\n",
    "\n",
    "    '''\n",
    "    top20.to_csv(out_csv, index=False)\n",
    "    with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\") as writer:\n",
    "        top20.to_excel(writer, index=False, sheet_name=\"CDP_2025\")\n",
    "\n",
    "    print(f\"\\nSaved: {out_csv.resolve()}\")\n",
    "    print(f\"Saved: {out_xlsx.resolve()}\")\n",
    "    '''\n",
    "    \n",
    "    # Demonstrate step-by-step math for a few cities (you can change the list)\n",
    "    for city in [\"Mumbai (MMR)\", \"Delhi (NCR)\"]:\n",
    "        explain_city(df, city)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaf30f5-99cd-4ba7-a081-5c083fe1bbb1",
   "metadata": {},
   "source": [
    "## Demand Allocation across Demand Centres ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94886862-96bd-437b-8548-541d0d87c401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Urban gifting pool allocated to Top-20 cities: 27,000 t\n",
      "Top-20 total demand pool (assumed 70% of 210,000 t): 147,000 t\n",
      "\n",
      "Top-20 city allocation (shares, totals, gifting and %):\n",
      " rank           city          state    share total_demand_tonnes_city gifting_tonnes_city gifting_pct_of_city_demand\n",
      "    1    Delhi (NCR)          Delhi 14.5006%                   21,316               3,915                     18.37%\n",
      "    2   Mumbai (MMR)    Maharashtra 10.8472%                   15,945               2,929                     18.37%\n",
      "    3      Bengaluru      Karnataka  9.0803%                   13,348               2,452                     18.37%\n",
      "    4      Hyderabad      Telangana  8.5190%                   12,523               2,300                     18.37%\n",
      "    5        Chennai     Tamil Nadu  8.2729%                   12,161               2,234                     18.37%\n",
      "    6        Kolkata    West Bengal  7.7784%                   11,434               2,100                     18.37%\n",
      "    7      Ahmedabad        Gujarat  7.1000%                   10,437               1,917                     18.37%\n",
      "    8          Surat        Gujarat  6.2775%                    9,228               1,695                     18.37%\n",
      "    9 Pune (PCMC UA)    Maharashtra  6.0685%                    8,921               1,638                     18.37%\n",
      "   10         Jaipur      Rajasthan  3.3496%                    4,924                 904                     18.37%\n",
      "   11         Nagpur    Maharashtra  2.7790%                    4,085                 750                     18.37%\n",
      "   12        Lucknow  Uttar Pradesh  2.6613%                    3,912                 719                     18.37%\n",
      "   13         Indore Madhya Pradesh  2.4218%                    3,560                 654                     18.37%\n",
      "   14     Coimbatore     Tamil Nadu  2.3417%                    3,442                 632                     18.37%\n",
      "   15         Kanpur  Uttar Pradesh  2.2833%                    3,356                 616                     18.37%\n",
      "   16          Patna          Bihar  1.4945%                    2,197                 404                     18.37%\n",
      "   17         Bhopal Madhya Pradesh  1.4301%                    2,102                 386                     18.37%\n",
      "   18       Vadodara        Gujarat  1.4174%                    2,084                 383                     18.37%\n",
      "   19  Visakhapatnam Andhra Pradesh  1.3768%                    2,024                 372                     18.37%\n",
      "   20          Kochi         Kerala  0.0000%                        0                   0                        NaN\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Distribute 30,000 tonnes of gifting chocolate to Top-20 cities (urban = 90%),\n",
    "compute each city's demand share, gifting tonnes, and gifting % of that city's demand.\n",
    "\n",
    "ASSUMPTIONS\n",
    "-----------\n",
    "1) Urban gifting allocated to Top-20 = 90% * 30,000 = 27,000 t\n",
    "2) City shares are proportional to CDP (relative demand score).\n",
    "3) National total demand proxy = 210,000 t (from case totals).\n",
    "4) Top-20 cities account for 70% of national demand -> 147,000 t pooled across Top-20.\n",
    "   Change TOP20_SHARE_OF_NATIONAL if you want a different concentration.\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass, asdict\n",
    "from math import log\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# Inputs you can tweak\n",
    "# ----------------------------\n",
    "NATIONAL_TOTAL_TONNES = 210_000    # from case totals (Affordable + Premium + Gifting)\n",
    "TOTAL_GIFTING_TONNES   = 30_000    # from case (Assorted/Gifting)\n",
    "URBAN_SHARE_TO_TOP20   = 0.90      # per your instruction\n",
    "TOP20_SHARE_OF_NATIONAL = 0.70     # assumption (urban concentration); tweak to 0.65/0.75 etc.\n",
    "\n",
    "@dataclass\n",
    "class City:\n",
    "    name: str\n",
    "    state: str\n",
    "    population_2025: int\n",
    "    pop_source: str\n",
    "    blinkit: int\n",
    "    instamart: int\n",
    "    zepto: int\n",
    "\n",
    "# 20-city set + quick-commerce flags (presence=1/absence=0)\n",
    "CITIES: List[City] = [\n",
    "    City(\"Delhi (NCR)\",         \"Delhi\",         35700000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Mumbai (MMR)\",        \"Maharashtra\",   27600000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Bengaluru\",           \"Karnataka\",     14700000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Hyderabad\",           \"Telangana\",     11700000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Chennai\",             \"Tamil Nadu\",    12900000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Kolkata\",             \"West Bengal\",   17900000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Ahmedabad\",           \"Gujarat\",        9900000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Surat\",               \"Gujarat\",        8050000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Pune (PCMC UA)\",      \"Maharashtra\",    8000000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Jaipur\",              \"Rajasthan\",      4525000, \"CityPopulation 2025 agglomerations\", 1, 1, 1),\n",
    "    City(\"Nagpur\",              \"Maharashtra\",    3575000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "    City(\"Lucknow\",             \"Uttar Pradesh\",  4225000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "    City(\"Indore\",              \"Madhya Pradesh\", 3750000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "    City(\"Coimbatore\",          \"Tamil Nadu\",     3075000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "    City(\"Kanpur\",              \"Uttar Pradesh\",  3700000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "    City(\"Patna\",               \"Bihar\",          2950000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "    City(\"Bhopal\",              \"Madhya Pradesh\", 2686000, \"Macrotrends/WPR 2025 metro\",         1, 1, 0),\n",
    "    City(\"Vadodara\",            \"Gujarat\",        2425000, \"Macrotrends/WPR 2025 metro\",         1, 1, 0),\n",
    "    City(\"Visakhapatnam\",       \"Andhra Pradesh\", 2440000, \"Macrotrends/WPR 2025 metro\",         1, 1, 0),\n",
    "    City(\"Kochi\",               \"Kerala\",         1660000, \"CityPopulation 2025 agglomerations\", 1, 1, 0),\n",
    "]\n",
    "\n",
    "STATE_NSDP_2024_25: Dict[str, int] = {  # ₹ per capita, FY 2024–25 (MOSPI / Wikipedia table)\n",
    "    \"Delhi\":          513_131,\n",
    "    \"Maharashtra\":    309_340,\n",
    "    \"Karnataka\":      380_906,\n",
    "    \"Telangana\":      427_730,\n",
    "    \"Tamil Nadu\":     350_695,\n",
    "    \"West Bengal\":    171_184,\n",
    "    \"Gujarat\":        336_875,\n",
    "    \"Rajasthan\":      187_454,\n",
    "    \"Uttar Pradesh\":  127_468,\n",
    "    \"Madhya Pradesh\": 156_381,\n",
    "    \"Bihar\":           68_828,\n",
    "    \"Kerala\":         317_723,\n",
    "    \"Andhra Pradesh\": 298_058,\n",
    "}\n",
    "\n",
    "def normalize_log_pop(series: pd.Series) -> pd.Series:\n",
    "    ln = np.log(series.astype(float))\n",
    "    return (ln - ln.min()) / (ln.max() - ln.min())\n",
    "\n",
    "def normalize_minmax(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype(float)\n",
    "    return (s - s.min()) / (s.max() - s.min())\n",
    "\n",
    "def compute_cdp(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Population and affluence indices\n",
    "    df[\"pop_index\"] = normalize_log_pop(df[\"population_2025\"])\n",
    "    df[\"nsdp_pc_2024_25\"] = df[\"state\"].map(STATE_NSDP_2024_25)\n",
    "    df[\"affluence_index\"] = normalize_minmax(df[\"nsdp_pc_2024_25\"])\n",
    "    # Quick-commerce availability score\n",
    "    df[\"qcas\"] = (df[\"blinkit\"] + df[\"instamart\"] + df[\"zepto\"]) / 3.0\n",
    "    # Traditional & Modern components\n",
    "    df[\"TC\"] = df[\"pop_index\"] * (0.6 + 0.4 * df[\"affluence_index\"])\n",
    "    df[\"MC\"] = df[\"pop_index\"] * (0.4 * df[\"affluence_index\"] + 0.6 * df[\"qcas\"])\n",
    "    # Final CDP score (75% traditional)\n",
    "    df[\"cdp\"] = 0.75*df[\"TC\"] + 0.25*df[\"MC\"]\n",
    "    return df\n",
    "\n",
    "def build_city_df(cities: List[City]) -> pd.DataFrame:\n",
    "    df = pd.DataFrame([asdict(c) for c in cities])\n",
    "    df.rename(columns={\"name\": \"city\"}, inplace=True)\n",
    "    df = compute_cdp(df)\n",
    "    return df\n",
    "\n",
    "def allocate(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Implements the 3 steps:\n",
    "    1) City shares s_i from CDP (sum to 1) and gifting urban allocation Gi.\n",
    "    2) City total demand Di from Top-20 pool and gifting % of city.\n",
    "    3) Outputs both tonnes and percentages.\n",
    "    \"\"\"\n",
    "    # 1) Shares and gifting allocation\n",
    "    df[\"share\"] = df[\"cdp\"] / df[\"cdp\"].sum()\n",
    "    gifting_pool_top20 = TOTAL_GIFTING_TONNES * URBAN_SHARE_TO_TOP20  # 27,000 t\n",
    "    df[\"gifting_tonnes_city\"] = df[\"share\"] * gifting_pool_top20\n",
    "\n",
    "    # 2) City total demand allocation from Top-20 pool\n",
    "    top20_demand_pool = NATIONAL_TOTAL_TONNES * TOP20_SHARE_OF_NATIONAL  # 147,000 t (assumed)\n",
    "    df[\"total_demand_tonnes_city\"] = df[\"share\"] * top20_demand_pool\n",
    "\n",
    "    # 2b) Gifting % of each city's demand\n",
    "    df[\"gifting_pct_of_city_demand\"] = np.where(\n",
    "        df[\"total_demand_tonnes_city\"] > 0,\n",
    "        100.0 * df[\"gifting_tonnes_city\"] / df[\"total_demand_tonnes_city\"],\n",
    "        np.nan\n",
    "    )\n",
    "\n",
    "    # Formatting and ranking\n",
    "    df_sorted = df.sort_values(\"cdp\", ascending=False).reset_index(drop=True)\n",
    "    df_sorted[\"rank\"] = range(1, len(df_sorted)+1)\n",
    "\n",
    "    # Sanity checks\n",
    "    assert abs(df_sorted[\"share\"].sum() - 1.0) < 1e-9, \"Shares must sum to 1\"\n",
    "    # Return friendly columns\n",
    "    cols = [\n",
    "        \"rank\",\"city\",\"state\",\n",
    "        \"share\",\"total_demand_tonnes_city\",\n",
    "        \"gifting_tonnes_city\",
    "    ]\n",
    "    return df_sorted[cols], gifting_pool_top20, top20_demand_pool\n",
    "\n",
    "def main():\n",
    "    df = build_city_df(CITIES)\n",
    "    out, gifting_pool_top20, top20_demand_pool = allocate(df)\n",
    "\n",
    "    # Pretty print\n",
    "    print(f\"\\nUrban gifting pool allocated to Top-20 cities: {gifting_pool_top20:,.0f} t\")\n",
    "    print(f\"Top-20 total demand pool (assumed {TOP20_SHARE_OF_NATIONAL*100:.0f}% of {NATIONAL_TOTAL_TONNES:,} t): {top20_demand_pool:,.0f} t\")\n",
    "    print(\"\\nTop-20 city allocation (shares, totals, gifting and %):\")\n",
    "    print(out.to_string(index=False, formatters={\n",
    "        \"share\": \"{:.4%}\".format,\n",
    "        \"total_demand_tonnes_city\": \"{:,.0f}\".format,\n",
    "        \"gifting_tonnes_city\": \"{:,.0f}\".format,\n",
    "    "    }))\n",
    "\n",
    "    '''\n",
    "    # Save CSV/Excel\n",
    "    out_csv = Path(\"top20_gifting_allocation.csv\")\n",
    "    out_xlsx = Path(\"top20_gifting_allocation.xlsx\")\n",
    "    out.to_csv(out_csv, index=False)\n",
    "    with pd.ExcelWriter(out_xlsx, engine=\"openpyxl\") as writer:\n",
    "        out.to_excel(writer, index=False, sheet_name=\"Allocation\")\n",
    "    print(f\"\\nSaved: {out_csv.resolve()}\")\n",
    "    print(f\"Saved: {out_xlsx.resolve()}\")\n",
    "    '''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a15d9b-3aa7-4071-963d-bb8d07a52ccd",
   "metadata": {},
   "source": [
    "## Road Distance Calculation from Plants to Demand Centres ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14e74dc9-a09e-42e4-8317-b6fcaaa61d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Distance matrix between 20 demand cities and 5 gifting plants in India.\n",
    "- Straight-line distance: Haversine (km)\n",
    "- Road distance: OSRM Table API (km), no API key needed\n",
    "\n",
    "Notes:\n",
    "- OSRM demo server is rate-limited and best-effort. For heavy/production use,\n",
    "  run your own OSRM backend or call in smaller batches.\n",
    "- Coordinates are approximate city centroids. Adjust if you want exact plant/warehouse pins.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# Cities & plant coordinates\n",
    "# (lat, lon) in decimal degrees\n",
    "# ----------------------------\n",
    "coords = {\n",
    "    # Demand cities (20)\n",
    "    \"Delhi NCR\":       (28.6139, 77.2090),\n",
    "    \"Mumbai\":          (19.0760, 72.8777),\n",
    "    \"Bengaluru\":       (12.9716, 77.5946),\n",
    "    \"Hyderabad\":       (17.3850, 78.4867),\n",
    "    \"Chennai\":         (13.0827, 80.2707),\n",
    "    \"Kolkata\":         (22.5726, 88.3639),\n",
    "    \"Ahmedabad\":       (23.0225, 72.5714),\n",
    "    \"Surat\":           (21.1702, 72.8311),\n",
    "    \"Pune\":            (18.5204, 73.8567),\n",
    "    \"Jaipur\":          (26.9124, 75.7873),\n",
    "    \"Nagpur\":          (21.1458, 79.0882),\n",
    "    \"Lucknow\":         (26.8467, 80.9462),\n",
    "    \"Indore\":          (22.7196, 75.8577),\n",
    "    \"Coimbatore\":      (11.0168, 76.9558),\n",
    "    \"Kanpur\":          (26.4499, 80.3319),\n",
    "    \"Patna\":           (25.5941, 85.1376),\n",
    "    \"Bhopal\":          (23.2599, 77.4126),\n",
    "    \"Vadodara\":        (22.3072, 73.1812),\n",
    "    \"Visakhapatnam\":   (17.6868, 83.2185),\n",
    "    \"Kochi\":           (9.9312, 76.2673),\n",
    "\n",
    "    # Gifting plants (5)\n",
    "    \"Gurgaon\":         (28.4595, 77.0266),\n",
    "    \"Bhopal_Plant\":    (23.2599, 77.4126),   # separate key to avoid name clash with city row label (optional)\n",
    "    \"Rajkot\":          (22.3039, 70.8022),\n",
    "    \"Kolkata_Plant\":   (22.5726, 88.3639),   # same centroid as city; adjust to exact plant pin if available\n",
    "    \"Hyderabad_Plant\": (17.3850, 78.4867),\n",
    "}\n",
    "\n",
    "# Define source (rows) and destination (columns) sets\n",
    "demand_cities = [\n",
    "    \"Delhi NCR\",\"Mumbai\",\"Bengaluru\",\"Hyderabad\",\"Chennai\",\"Kolkata\",\"Ahmedabad\",\"Surat\",\"Pune\",\"Jaipur\",\n",
    "    \"Nagpur\",\"Lucknow\",\"Indore\",\"Coimbatore\",\"Kanpur\",\"Patna\",\"Bhopal\",\"Vadodara\",\"Visakhapatnam\",\"Kochi\"\n",
    "]\n",
    "plants = [\"Gurgaon\",\"Bhopal_Plant\",\"Rajkot\",\"Kolkata_Plant\",\"Hyderabad_Plant\"]\n",
    "\n",
    "# ----------------------------\n",
    "# Haversine (straight-line, km)\n",
    "# ----------------------------\n",
    "def haversine_km(a, b):\n",
    "    R = 6371.0  # km\n",
    "    lat1, lon1 = a\n",
    "    lat2, lon2 = b\n",
    "    # Convert to radians\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlmb = math.radians(lon2 - lon1)\n",
    "    # Haversine\n",
    "    s = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlmb/2)**2\n",
    "    c = 2*math.atan2(math.sqrt(s), math.sqrt(1-s))\n",
    "    return R * c\n",
    "\n",
    "def build_straight_matrix():\n",
    "    rows = []\n",
    "    for city in demand_cities:\n",
    "        row = {}\n",
    "        for plant in plants:\n",
    "            d = haversine_km(coords[city], coords[plant])\n",
    "            row[plant] = round(d, 1)\n",
    "        rows.append({\"city\": city, **row})\n",
    "    return pd.DataFrame(rows).set_index(\"city\")\n",
    "\n",
    "# ----------------------------\n",
    "# OSRM Table API (road distance, km)\n",
    "# ----------------------------\n",
    "def osrm_table_road_km():\n",
    "    \"\"\"\n",
    "    Builds a rectangular (20 x 5) distance matrix using OSRM table service.\n",
    "    Returns a DataFrame with demand cities as rows and plants as columns.\n",
    "    \"\"\"\n",
    "    base = \"https://router.project-osrm.org/table/v1/driving/\"\n",
    "    # OSRM expects coords as lon,lat; we will concatenate [sources + destinations]\n",
    "    src_coords = [coords[c] for c in demand_cities]\n",
    "    dst_coords = [coords[p] for p in plants]\n",
    "    all_coords = src_coords + dst_coords\n",
    "\n",
    "    # Build coord string: lon,lat;lon,lat;...\n",
    "    coord_str = \";\".join([f\"{lon:.6f},{lat:.6f}\" for (lat, lon) in all_coords])\n",
    "\n",
    "    # Source indices are the first N sources; destinations are the last M\n",
    "    n_src = len(src_coords)\n",
    "    n_dst = len(dst_coords)\n",
    "    sources_param = \";\".join(str(i) for i in range(n_src))\n",
    "    destinations_param = \";\".join(str(i) for i in range(n_src, n_src + n_dst))\n",
    "\n",
    "    url = (\n",
    "        f\"{base}{coord_str}\"\n",
    "        f\"?sources={sources_param}\"\n",
    "        f\"&destinations={destinations_param}\"\n",
    "        f\"&annotations=distance\"\n",
    "    )\n",
    "\n",
    "    resp = requests.get(url, timeout=60)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    # distances is a list of lists [rows = sources, cols = destinations], in meters\n",
    "    dist_matrix_m = data.get(\"distances\")\n",
    "    if dist_matrix_m is None:\n",
    "        raise RuntimeError(f\"OSRM response missing 'distances': {data}\")\n",
    "\n",
    "    # Convert to km and build DataFrame\n",
    "    dist_km = [[(v/1000.0 if v is not None else None) for v in row] for row in dist_matrix_m]\n",
    "    df = pd.DataFrame(dist_km, index=demand_cities, columns=plants)\n",
    "    # Round to 1 decimal place for display\n",
    "    return df.round(1)\n",
    "\n",
    "# ----------------------------\n",
    "# Main: build and export\n",
    "# ----------------------------\n",
    "def main():\n",
    "    # Straight-line matrix\n",
    "    df_straight = build_straight_matrix()\n",
    "\n",
    "    # Road matrix via OSRM\n",
    "    try:\n",
    "        df_road = osrm_table_road_km()\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] OSRM road distance failed: {e}\")\n",
    "        print(\"Falling back to straight-line distances for the 'Road_km' sheet.\")\n",
    "        df_road = df_straight.copy()\n",
    "\n",
    "    '''\n",
    "    # Save to Excel and CSV\n",
    "    out_xlsx = Path(\"city_plant_distances.xlsx\")\n",
    "    out_csv  = Path(\"city_plant_distances.csv\")\n",
    "    with pd.ExcelWriter(out_xlsx) as writer:\n",
    "        df_straight.to_excel(writer, sheet_name=\"Straight_Line_km\")\n",
    "        df_road.to_excel(writer, sheet_name=\"Road_km\")\n",
    "\n",
    "    # Optionally, save road distances as a tidy CSV\n",
    "    df_road_reset = df_road.reset_index().rename(columns={\"index\": \"city\"})\n",
    "    df_road_reset.to_csv(out_csv, index=False)\n",
    "\n",
    "    print(f\"Saved: {out_xlsx.resolve()}\")\n",
    "    print(f\"Saved: {out_csv.resolve()}\")\n",
    "    '''\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dbfa49-8875-4376-907a-24224cd6e470",
   "metadata": {},
   "source": [
    "## Scenario 1 - Optimal Production Planning with existing capacity to serve Demand Centres ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "545f209e-5b9b-49b7-901c-db7748b0c184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal total transport cost (INR): 49,684,155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WRITAM\\AppData\\Local\\Temp\\ipykernel_30836\\752192583.py:120: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  model += pulp.lpSum(x[(i, j)] for j in plants) == float(dem.loc[dem[\"city\"] == i, \"demand_t\"])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Min-cost allocation from plants to cities using a transportation LP.\n",
    "\n",
    "INPUTS REQUIRED\n",
    "---------------\n",
    "1) City demand CSV with at least:\n",
    "   - 'city' column\n",
    "   - demand column (default 'gifting_tonnes_city') for each of the 20 cities\n",
    "\n",
    "2) Distance matrix Excel with sheets (preferred -> fallback):\n",
    "   - 'Road_km'           # rows=cities, cols=plants, values=km\n",
    "   - 'Straight_Line_km'  # optional fallback\n",
    "\n",
    "PARAMETERS TO EDIT\n",
    "------------------\n",
    "- PLANTS: list of plant column names exactly as in your distance matrix\n",
    "- CAPACITY_PER_PLANT_TONNES: default 6000 (for 6 plants)\n",
    "- COST_PER_TON_KM: default 4.0 INR per ton-km (ambient FTL mid-point)\n",
    "- REEFER_MULTIPLIER: multiply cost if refrigerated is used\n",
    "- USE_ROAD_DISTANCES_FIRST: True to prefer road km\n",
    "- DETOUR_FACTOR: if Road_km missing, multiply straight-line by this factor\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import pulp\n",
    "\n",
    "# --------------------\n",
    "# FILE PATHS (EDIT)\n",
    "# --------------------\n",
    "DEMAND_CSV = Path(\"top20_gifting_allocation.csv\")       # from previous step\n",
    "DIST_XLSX  = Path(\"city_plant_final.xlsx\")          # from your OSRM/Google output\n",
    "\n",
    "# --------------------\n",
    "# MODEL PARAMS (EDIT)\n",
    "# --------------------\n",
    "DEMAND_COL = \"gifting_tonnes_city\"     # or 'total_demand_tonnes_city' if you want total demand\n",
    "PLANTS: List[str] = [\n",
    "    # Ensure these names match the columns in your distance matrix file\n",
    "    \"Gurgaon_Plant\", \"Bhopal_Plant\", \"Rajkot_Plant\", \"Kolkata_Plant\", \"Hyderabad_Plant\"\n",
    "]\n",
    "\n",
    "CAPACITY_PER_PLANT_TONNES = 5400.0\n",
    "PLANT_CAPACITY: Dict[str, float] = {p: CAPACITY_PER_PLANT_TONNES for p in PLANTS}\n",
    "\n",
    "COST_PER_TON_KM   = 4.0     # INR per ton-km (ambient)  [assumption, see notes]\n",
    "REEFER_MULTIPLIER = 1.0     # set to 1.4~1.6 if you need reefer premium\n",
    "USE_ROAD_DISTANCES_FIRST = True\n",
    "DETOUR_FACTOR = 1.30        # used only if Road_km not available\n",
    "\n",
    "# --------------------\n",
    "# LOAD INPUTS\n",
    "# --------------------\n",
    "# 1) Demand\n",
    "dem = pd.read_csv(DEMAND_CSV)\n",
    "dem = dem[[\"city\", DEMAND_COL]].copy().rename(columns={DEMAND_COL: \"demand_t\"})\n",
    "dem[\"demand_t\"] = dem[\"demand_t\"].astype(float)\n",
    "\n",
    "# 2) Distance matrix (km)\n",
    "xl = pd.ExcelFile(DIST_XLSX)\n",
    "sheet_to_use = None\n",
    "\n",
    "if USE_ROAD_DISTANCES_FIRST and \"Road_km\" in xl.sheet_names:\n",
    "    sheet_to_use = \"Road_km\"\n",
    "elif \"Straight_Line_km\" in xl.sheet_names:\n",
    "    sheet_to_use = \"Straight_Line_km\"\n",
    "else:\n",
    "    raise FileNotFoundError(\"No 'Road_km' or 'Straight_Line_km' sheet found in distance workbook.\")\n",
    "\n",
    "dist_df = pd.read_excel(DIST_XLSX, sheet_name=sheet_to_use)\n",
    "\n",
    "# if first column holds the city names, rename it:\n",
    "if dist_df.columns[0].startswith(\"Unnamed\"):\n",
    "    dist_df.rename(columns={dist_df.columns[0]: \"city\"}, inplace=True)\n",
    "\n",
    "dist_df = dist_df.set_index(\"city\")\n",
    "\n",
    "# If we're on straight-line sheet and you want to approximate road:\n",
    "if sheet_to_use == \"Straight_Line_km\" and USE_ROAD_DISTANCES_FIRST:\n",
    "    dist_df = dist_df * DETOUR_FACTOR\n",
    "\n",
    "# Check columns and align\n",
    "missing_plants = [p for p in PLANTS if p not in dist_df.columns]\n",
    "if missing_plants:\n",
    "    raise ValueError(f\"Plants {missing_plants} not present as columns in distance sheet '{sheet_to_use}'.\")\n",
    "\n",
    "# Keep only our cities, in order\n",
    "dist_df = dist_df.loc[dem[\"city\"]]\n",
    "\n",
    "# --------------------\n",
    "# COST MATRIX (INR per ton)\n",
    "# --------------------\n",
    "effective_cost_per_ton_km = COST_PER_TON_KM * REEFER_MULTIPLIER\n",
    "cost_df = dist_df * effective_cost_per_ton_km  # INR per ton to ship from plant->city\n",
    "\n",
    "# --------------------\n",
    "# TRANSPORTATION LP\n",
    "# --------------------\n",
    "cities = list(dem[\"city\"])\n",
    "plants = PLANTS\n",
    "\n",
    "# Decision vars: x[(i,j)] tonnes from plant j to city i\n",
    "x = pulp.LpVariable.dicts(\"x\",\n",
    "                          ((i, j) for i in cities for j in plants),\n",
    "                          lowBound=0,\n",
    "                          cat=\"Continuous\")\n",
    "\n",
    "# Model\n",
    "model = pulp.LpProblem(\"MinCostTransport\", pulp.LpMinimize)\n",
    "\n",
    "# Objective\n",
    "model += pulp.lpSum(x[(i, j)] * cost_df.loc[i, j] for i in cities for j in plants)\n",
    "\n",
    "# Constraints: city demand\n",
    "for i in cities:\n",
    "    model += pulp.lpSum(x[(i, j)] for j in plants) == float(dem.loc[dem[\"city\"] == i, \"demand_t\"])\n",
    "\n",
    "# Constraints: plant capacity\n",
    "for j in plants:\n",
    "    model += pulp.lpSum(x[(i, j)] for i in cities) <= PLANT_CAPACITY[j]\n",
    "\n",
    "# Solve (CBC default)\n",
    "status = model.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "if pulp.LpStatus[status] != \"Optimal\":\n",
    "    print(f\"[WARN] Solver status: {pulp.LpStatus[status]}\")\n",
    "\n",
    "# --------------------\n",
    "# OUTPUTS\n",
    "# --------------------\n",
    "# Flow matrix\n",
    "flows = pd.DataFrame(0.0, index=cities, columns=plants)\n",
    "for i in cities:\n",
    "    for j in plants:\n",
    "        flows.loc[i, j] = x[(i, j)].value() if x[(i, j)].value() is not None else 0.0\n",
    "\n",
    "# Summaries\n",
    "city_served = flows.sum(axis=1).rename(\"served_t\")\n",
    "plant_used  = flows.sum(axis=0).rename(\"used_t\")\n",
    "total_cost  = float(pulp.value(model.objective))\n",
    "\n",
    "# Combine nice views\n",
    "result_city = pd.concat([dem.set_index(\"city\"), city_served], axis=1)\n",
    "result_city[\"gap_t\"] = result_city[\"demand_t\"] - result_city[\"served_t\"]\n",
    "\n",
    "result_plant = pd.DataFrame({\n",
    "    \"capacity_t\": pd.Series(PLANT_CAPACITY),\n",
    "    \"used_t\": plant_used,\n",
    "})\n",
    "result_plant[\"slack_t\"] = result_plant[\"capacity_t\"] - result_plant[\"used_t\"]\n",
    "\n",
    "'''\n",
    "# Save\n",
    "out_xlsx = Path(\"optimal_allocation.xlsx\")\n",
    "out_csv_flows = Path(\"optimal_flows_matrix.csv\")\n",
    "\n",
    "with pd.ExcelWriter(out_xlsx) as writer:\n",
    "    flows.to_excel(writer, sheet_name=\"Flows_tonnes\")          # city x plant\n",
    "    cost_df.to_excel(writer, sheet_name=\"Cost_per_ton_INR\")    # INR/ton\n",
    "    (flows * dist_df).to_excel(writer, sheet_name=\"Ton_km\")    # ton*km (for reference)\n",
    "    result_city.to_excel(writer, sheet_name=\"City_Summary\")\n",
    "    result_plant.to_excel(writer, sheet_name=\"Plant_Summary\")\n",
    "    pd.DataFrame({\"Total_Cost_INR\": [total_cost]}).to_excel(writer, sheet_name=\"Objective\")\n",
    "\n",
    "flows.reset_index().to_csv(out_csv_flows, index=False)\n",
    "'''\n",
    "print(f\"Optimal total transport cost (INR): {total_cost:,.0f}\")\n",
    "#print(f\"Saved workbook: {out_xlsx.resolve()}\")\n",
    "#print(f\"Saved flows CSV: {out_csv_flows.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401ab1d2-65c0-41c8-9101-70eb3fb4a869",
   "metadata": {},
   "source": [
    "## Scenario 2 - Optimal Production Planning with unconstrained capacity for 5 Plants ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76474403-5f69-455d-bdd5-328156699a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unconstrained min-cost plan (5 plants) ===\n",
      "Total ton-km: 9299440.1\n",
      "Total transport cost (INR): 37,197,760.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WRITAM\\AppData\\Local\\Temp\\ipykernel_30836\\598702773.py:110: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  demand_t = float(dem.loc[dem[\"city\"] == city, \"demand_t\"])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Min-cost production/dispatch plan from 5 plants to 20 cities (NO capacity limits).\n",
    "Each city is fully served by the cheapest plant (per ton cost).\n",
    "\n",
    "Inputs\n",
    "------\n",
    "1) Demand CSV: 'top20_gifting_allocation.csv' with columns ['city', 'gifting_tonnes_city'].\n",
    "   - Change DEMAND_COL if using another column.\n",
    "2) Distance Excel: 'city_plant_distances.xlsx' with sheets:\n",
    "   - 'Road_km' (preferred) OR\n",
    "   - 'Straight_Line_km' (fallback; multiplied by DETOUR_FACTOR if USE_ROAD_FIRST=True)\n",
    "\n",
    "Plants (5)\n",
    "----------\n",
    "['Gurgaon','Bhopal','Rajkot','Kolkata','Hyderabad']\n",
    "\n",
    "Outputs\n",
    "-------\n",
    "- production_plan_5plants_unconstrained.xlsx\n",
    "- production_flows_5plants_unconstrained.csv\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------- FILES --------\n",
    "DEMAND_CSV = Path(\"top20_gifting_allocation.csv\")\n",
    "DIST_XLSX  = Path(\"city_plant_final.xlsx\")\n",
    "\n",
    "# -------- SETTINGS --------\n",
    "DEMAND_COL = \"gifting_tonnes_city\"\n",
    "PLANTS = [\"Gurgaon\",\"Bhopal\",\"Rajkot\",\"Kolkata\",\"Hyderabad\"]\n",
    "COST_PER_TON_KM = 4.0   # INR per ton-km (assumption based on NITI/World Bank/market)\n",
    "REEFER_MULTIPLIER = 1.0 # set 1.3–1.6 for reefer premium if needed\n",
    "USE_ROAD_FIRST = True\n",
    "DETOUR_FACTOR = 1.30    # if only straight-line is available and you want road approximation\n",
    "\n",
    "# Handle column name variants (if your distance file used *_Plant headers)\n",
    "PLANT_RENAME = {\n",
    "    \"Bhopal_Plant\": \"Bhopal\",\n",
    "    \"Kolkata_Plant\": \"Kolkata\",\n",
    "    \"Hyderabad_Plant\": \"Hyderabad\",\n",
    "    \"Gurgaon_Plant\": \"Gurgaon\",\n",
    "    \"Rajkot_Plant\": \"Rajkot\",\n",
    "}\n",
    "# Normalize city labels from earlier steps\n",
    "CITY_RENAME = {\n",
    "    \"Delhi (NCR)\": \"Delhi NCR\",\n",
    "    \"Mumbai (MMR)\": \"Mumbai\",\n",
    "    \"Pune (PCMC UA)\": \"Pune\",\n",
    "}\n",
    "\n",
    "# -------- LOAD DEMAND --------\n",
    "dem = pd.read_csv(DEMAND_CSV)\n",
    "dem[\"city\"] = dem[\"city\"].astype(str).str.strip().replace(CITY_RENAME)\n",
    "dem = dem[[\"city\", DEMAND_COL]].rename(columns={DEMAND_COL: \"demand_t\"})\n",
    "dem[\"demand_t\"] = dem[\"demand_t\"].astype(float)\n",
    "\n",
    "# -------- LOAD DISTANCES --------\n",
    "xl = pd.ExcelFile(DIST_XLSX)\n",
    "sheet = \"Road_km\" if (USE_ROAD_FIRST and \"Road_km\" in xl.sheet_names) else \\\n",
    "        (\"Straight_Line_km\" if \"Straight_Line_km\" in xl.sheet_names else None)\n",
    "if sheet is None:\n",
    "    raise FileNotFoundError(\"Distance file must have 'Road_km' or 'Straight_Line_km'.\")\n",
    "\n",
    "dist_df = pd.read_excel(DIST_XLSX, sheet_name=sheet)\n",
    "\n",
    "# If first column is unlabeled index (cities), fix it\n",
    "if dist_df.columns[0].startswith(\"Unnamed\"):\n",
    "    dist_df.rename(columns={dist_df.columns[0]: \"city\"}, inplace=True)\n",
    "# Set index to city\n",
    "if \"city\" in dist_df.columns:\n",
    "    dist_df = dist_df.set_index(\"city\")\n",
    "else:\n",
    "    dist_df = dist_df.set_index(dist_df.columns[0])\n",
    "\n",
    "# Clean up names, align to canonical plants\n",
    "dist_df.index = dist_df.index.astype(str).str.strip()\n",
    "dist_df.rename(columns={k: v for k, v in PLANT_RENAME.items() if k in dist_df.columns}, inplace=True)\n",
    "\n",
    "missing_cols = [p for p in PLANTS if p not in dist_df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Plants {missing_cols} not present as columns in '{sheet}'.\")\n",
    "\n",
    "# Align to demand city order & ensure all cities exist\n",
    "missing_cities = sorted(set(dem[\"city\"]) - set(dist_df.index))\n",
    "if missing_cities:\n",
    "    raise ValueError(f\"These demand cities not found in distance matrix index: {missing_cities}\")\n",
    "dist_df = dist_df.loc[dem[\"city\"], PLANTS]\n",
    "\n",
    "# If we used straight-line but prefer road, detour to approximate\n",
    "if sheet == \"Straight_Line_km\" and USE_ROAD_FIRST:\n",
    "    dist_df = dist_df * DETOUR_FACTOR\n",
    "\n",
    "# -------- COST PER TON (INR/ton) --------\n",
    "rate = COST_PER_TON_KM * REEFER_MULTIPLIER\n",
    "cost_per_ton = dist_df * rate\n",
    "\n",
    "# -------- OPTIMAL ASSIGNMENT (no capacity) --------\n",
    "# For each city, pick plant with minimum cost per ton\n",
    "best_plant = cost_per_ton.idxmin(axis=1)            # plant name per city\n",
    "best_cost_per_ton = cost_per_ton.min(axis=1)        # INR/ton per city\n",
    "\n",
    "# Build flows: one non-zero per row (all demand to cheapest plant)\n",
    "flows = pd.DataFrame(0.0, index=dem[\"city\"], columns=PLANTS)\n",
    "for city, plant in best_plant.items():\n",
    "    demand_t = float(dem.loc[dem[\"city\"] == city, \"demand_t\"])\n",
    "    flows.loc[city, plant] = demand_t\n",
    "\n",
    "# Summaries\n",
    "plant_output = flows.sum(axis=0).rename(\"produced_t\")\n",
    "city_summary = dem.set_index(\"city\").copy()\n",
    "\n",
    "city_summary[\"assigned_plant\"] = best_plant\n",
    "city_summary[\"distance_km\"] = [dist_df.loc[city, plant] for city, plant in best_plant.items()]\n",
    "city_summary[\"cost_per_ton_INR\"] = best_cost_per_ton\n",
    "city_summary[\"lane_cost_INR\"] = city_summary[\"cost_per_ton_INR\"] * city_summary[\"demand_t\"]\n",
    "city_summary[\"ton_km\"] = city_summary[\"distance_km\"] * city_summary[\"demand_t\"]\n",
    "\n",
    "\n",
    "total_cost_inr = float(city_summary[\"lane_cost_INR\"].sum())\n",
    "total_ton_km = float(city_summary[\"ton_km\"].sum())\n",
    "\n",
    "'''\n",
    "# -------- SAVE --------\n",
    "out_xlsx = Path(\"production_plan_5plants_unconstrained.xlsx\")\n",
    "out_csv  = Path(\"production_flows_5plants_unconstrained.csv\")\n",
    "\n",
    "with pd.ExcelWriter(out_xlsx) as w:\n",
    "    dist_df.round(1).to_excel(w, sheet_name=\"Distance_km\")\n",
    "    (dist_df * rate).round(2).to_excel(w, sheet_name=\"Cost_INR_per_ton\")\n",
    "    flows.round(2).to_excel(w, sheet_name=\"Optimal_Flows_tonnes\")\n",
    "    plant_output.round(2).to_frame().to_excel(w, sheet_name=\"Plant_Output\")\n",
    "    city_summary.round(2).to_excel(w, sheet_name=\"City_Assignments\")\n",
    "    pd.DataFrame({\n",
    "        \"Total_ton_km\": [round(total_ton_km, 1)],\n",
    "        \"Total_Cost_INR\": [round(total_cost_inr, 2)]\n",
    "    }).to_excel(w, sheet_name=\"Objective\", index=False)\n",
    "\n",
    "flows.reset_index().rename(columns={\"index\": \"city\"}).round(2).to_csv(out_csv, index=False)\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"=== Unconstrained min-cost plan (5 plants) ===\")\n",
    "print(\"Total ton-km:\", round(total_ton_km, 1))\n",
    "print(\"Total transport cost (INR):\", f\"{total_cost_inr:,.2f}\")\n",
    "#print(\"Saved:\", out_xlsx.resolve())\n",
    "#print(\"Saved:\", out_csv.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9086a42-7ebd-4e8b-b7f8-92372fe50faa",
   "metadata": {},
   "source": [
    "## Scenario 3 - Find new co-packing unit ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab79b4bd-0acf-4279-aa40-713b65960624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver status: Optimal\n",
      "\n",
      "Selected NEW co-packer sites (5):\n",
      " - Mumbai @ (19.076, 72.8777)\n",
      " - Bengaluru @ (12.9716, 77.5946)\n",
      " - Ahmedabad @ (23.0225, 72.5714)\n",
      " - Surat @ (21.1702, 72.8311)\n",
      " - Lucknow @ (26.8467, 80.9462)\n",
      "\n",
      "Total ton-km: 2418110.3\n",
      "Total transport cost (INR): 9,672,441.28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Save Excel\\nout_xlsx = Path(\"new_copacker_site_selection.xlsx\")\\nwith pd.ExcelWriter(out_xlsx) as w:\\n    dist_df.round(1).to_excel(w, sheet_name=\"Distance_km\")\\n    cost_df.round(2).to_excel(w, sheet_name=\"Cost_INR_per_ton\")\\n    pd.DataFrame({\"site\": sites_all, \"open_y\": [y_val[s] for s in sites_all],\\n                 \"lat\": [COORDS[s][0] for s in sites_all],\\n                 \"lon\": [COORDS[s][1] for s in sites_all]}).to_excel(w, sheet_name=\"Sites\")\\n    pd.DataFrame({\"new_sites\": new_sites}).to_excel(w, sheet_name=\"Selected_New_Sites\", index=False)\\n    flows_df.to_excel(w, sheet_name=\"City_Assignments\", index=False)\\n\\nprint(f\"\\nSaved workbook: {out_xlsx.resolve()}\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Site selection for 5 new co-packing units (p-median with fixed existing plants).\n",
    "- Demand: 20 cities with gifting demand (tonnes)\n",
    "- Existing fixed plants: Gurgaon, Bhopal, Rajkot, Kolkata, Hyderabad\n",
    "- Candidates: (a) the 20 demand cities, (b) auto-generated midpoints between top-demand city pairs\n",
    "- Distance: OSRM road km (free), fallback to Haversine * detour\n",
    "- Objective: Minimize demand-weighted transport cost (ton-km * INR/ton-km)\n",
    "\n",
    "Outputs:\n",
    "- Selected new sites (5) + assignments of each city to nearest open site (existing or new)\n",
    "- Total ton-km and total INR cost\n",
    "- Excel with distances, costs, assignment matrix, and summaries\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import math\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pulp\n",
    "\n",
    "# ------------- FILES (edit paths if needed) -------------\n",
    "DEMAND_CSV = Path(\"top20_gifting_allocation.csv\")  # needs columns ['city','gifting_tonnes_city']\n",
    "# If you prefer total demand, change DEMAND_COL below.\n",
    "\n",
    "# ------------- SETTINGS -------------\n",
    "DEMAND_COL = \"gifting_tonnes_city\"\n",
    "COST_PER_TON_KM = 4.0     # INR per ton-km (assumption)\n",
    "DET_FALLBACK = 1.30       # multiplier on straight-line when OSRM not available\n",
    "USE_CANDIDATE_WITHIN_20 = True\n",
    "USE_CANDIDATE_MIDPOINTS = True\n",
    "TOP_PAIR_COUNT = 15       # number of high-demand pairs to generate midpoints for\n",
    "\n",
    "# Existing plants (fixed, always open)\n",
    "EXISTING_PLANTS = [\"Gurgaon\",\"Bhopal\",\"Rajkot\",\"Kolkata\",\"Hyderabad\"]\n",
    "\n",
    "FORBIDDEN_SITES = {\"Pune\", \"Chennai\"}  # not allowed as new sites\n",
    "\n",
    "# Coordinates dictionary (lat, lon) for demand cities + existing plants\n",
    "COORDS = {\n",
    "    # Demand cities (20)\n",
    "    \"Delhi NCR\":       (28.6139, 77.2090),\n",
    "    \"Mumbai\":          (19.0760, 72.8777),\n",
    "    \"Bengaluru\":       (12.9716, 77.5946),\n",
    "    \"Hyderabad\":       (17.3850, 78.4867),\n",
    "    \"Chennai\":         (13.0827, 80.2707),\n",
    "    \"Kolkata\":         (22.5726, 88.3639),\n",
    "    \"Ahmedabad\":       (23.0225, 72.5714),\n",
    "    \"Surat\":           (21.1702, 72.8311),\n",
    "    \"Pune\":            (18.5204, 73.8567),\n",
    "    \"Jaipur\":          (26.9124, 75.7873),\n",
    "    \"Nagpur\":          (21.1458, 79.0882),\n",
    "    \"Lucknow\":         (26.8467, 80.9462),\n",
    "    \"Indore\":          (22.7196, 75.8577),\n",
    "    \"Coimbatore\":      (11.0168, 76.9558),\n",
    "    \"Kanpur\":          (26.4499, 80.3319),\n",
    "    \"Patna\":           (25.5941, 85.1376),\n",
    "    \"Bhopal\":          (23.2599, 77.4126),\n",
    "    \"Vadodara\":        (22.3072, 73.1812),\n",
    "    \"Visakhapatnam\":   (17.6868, 83.2185),\n",
    "    \"Kochi\":           (9.9312, 76.2673),\n",
    "\n",
    "    # Existing plants (5)\n",
    "    \"Gurgaon\":         (28.4595, 77.0266),\n",
    "    \"Rajkot\":          (22.3039, 70.8022),\n",
    "    # Kolkata, Hyderabad, Bhopal already in above set; reused as plants too\n",
    "}\n",
    "\n",
    "# Canonical rename to avoid mismatches vs earlier CSVs\n",
    "CITY_RENAME = {\n",
    "    \"Delhi (NCR)\": \"Delhi NCR\",\n",
    "    \"Mumbai (MMR)\": \"Mumbai\",\n",
    "    \"Pune (PCMC UA)\": \"Pune\",\n",
    "}\n",
    "\n",
    "# ------------- HELPERS -------------\n",
    "def haversine_km(a, b):\n",
    "    R = 6371.0\n",
    "    lat1, lon1 = a\n",
    "    lat2, lon2 = b\n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlmb = math.radians(lon2 - lon1)\n",
    "    s = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlmb/2)**2\n",
    "    return R * (2*math.atan2(math.sqrt(s), math.sqrt(1-s)))\n",
    "\n",
    "def osrm_table_km(sources, destinations, coords_dict, timeout=60):\n",
    "    \"\"\"\n",
    "    Compute road distance matrix (km) between sources and destinations using OSRM public server.\n",
    "    Returns DataFrame (index=sources, columns=destinations) in km.\n",
    "    \"\"\"\n",
    "    base = \"https://router.project-osrm.org/table/v1/driving/\"\n",
    "    src_ll = [coords_dict[s] for s in sources]\n",
    "    dst_ll = [coords_dict[d] for d in destinations]\n",
    "    all_ll = src_ll + dst_ll\n",
    "    # OSRM expects lon,lat\n",
    "    coord_str = \";\".join([f\"{lon:.6f},{lat:.6f}\" for (lat, lon) in all_ll])\n",
    "\n",
    "    n_src = len(src_ll)\n",
    "    n_dst = len(dst_ll)\n",
    "    sources_param = \";\".join(str(i) for i in range(n_src))\n",
    "    destinations_param = \";\".join(str(i) for i in range(n_src, n_src+n_dst))\n",
    "\n",
    "    url = f\"{base}{coord_str}?sources={sources_param}&destinations={destinations_param}&annotations=distance\"\n",
    "    resp = requests.get(url, timeout=timeout)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    if \"distances\" not in data or data[\"distances\"] is None:\n",
    "        raise RuntimeError(f\"OSRM response missing 'distances': {data}\")\n",
    "    mat_m = data[\"distances\"]\n",
    "    mat_km = [[(v/1000.0 if v is not None else None) for v in row] for row in mat_m]\n",
    "    return pd.DataFrame(mat_km, index=sources, columns=destinations)\n",
    "\n",
    "def demand_weighted_pairs(cities, demand, top_n=15):\n",
    "    \"\"\"\n",
    "    Return top_n unique city pairs ranked by demand product (d_i * d_j), descending.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    for i, j in itertools.combinations(cities, 2):\n",
    "        pairs.append((i, j, demand[i] * demand[j]))\n",
    "    pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "    return pairs[:top_n]\n",
    "\n",
    "def midpoint(a, b):\n",
    "    return ((a[0]+b[0])/2.0, (a[1]+b[1])/2.0)\n",
    "\n",
    "# ------------- LOAD DEMAND -------------\n",
    "dem = pd.read_csv(DEMAND_CSV)\n",
    "dem[\"city\"] = dem[\"city\"].astype(str).str.strip().replace(CITY_RENAME)\n",
    "dem = dem[[\"city\", DEMAND_COL]].rename(columns={DEMAND_COL: \"demand_t\"})\n",
    "dem[\"demand_t\"] = dem[\"demand_t\"].astype(float)\n",
    "\n",
    "# Keep only our 20 cities present in COORDS\n",
    "dem = dem[dem[\"city\"].isin(COORDS.keys())].copy()\n",
    "dem.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Make dicts\n",
    "demand_dict = dict(zip(dem[\"city\"], dem[\"demand_t\"]))\n",
    "cities = list(demand_dict.keys())\n",
    "\n",
    "# ------------- BUILD CANDIDATE SET -------------\n",
    "candidates = []\n",
    "\n",
    "if USE_CANDIDATE_WITHIN_20:\n",
    "    # All demand cities can host a co-packer\n",
    "    candidates.extend(cities)\n",
    "\n",
    "if USE_CANDIDATE_MIDPOINTS:\n",
    "    pairs = demand_weighted_pairs(cities, demand_dict, top_n=TOP_PAIR_COUNT)\n",
    "    for i, j, _ in pairs:\n",
    "        mi = f\"Mid_{i[:6]}_{j[:6]}\"  # short label\n",
    "        # create midpoint coord\n",
    "        COORDS[mi] = midpoint(COORDS[i], COORDS[j])\n",
    "        candidates.append(mi)\n",
    "\n",
    "# Ensure uniqueness and remove any that clash with existing plant names accidentally\n",
    "candidates = [c for c in dict.fromkeys(candidates) if c not in EXISTING_PLANTS]\n",
    "\n",
    "# Ensure uniqueness and remove any that clash with existing plant names accidentally\n",
    "candidates = [c for c in dict.fromkeys(candidates) if c not in EXISTING_PLANTS]\n",
    "\n",
    "# NEW: drop forbidden cities from candidate sites\n",
    "candidates = [c for c in candidates if c not in FORBIDDEN_SITES]\n",
    "\n",
    "# Final site set = existing (fixed-open) + candidates (select 5)\n",
    "sites_all = EXISTING_PLANTS + candidates\n",
    "\n",
    "# ------------- DISTANCES (km) -------------\n",
    "# Try OSRM for road km; fallback to haversine * DET_FALLBACK\n",
    "try:\n",
    "    dist_df = osrm_table_km(cities, sites_all, COORDS)\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] OSRM failed ({e}). Falling back to Haversine * {DET_FALLBACK}.\")\n",
    "    rows = []\n",
    "    for i in cities:\n",
    "        row = {}\n",
    "        for s in sites_all:\n",
    "            d = haversine_km(COORDS[i], COORDS[s]) * DET_FALLBACK\n",
    "            row[s] = d\n",
    "        rows.append({\"city\": i, **row})\n",
    "    dist_df = pd.DataFrame(rows).set_index(\"city\")\n",
    "\n",
    "# ------------- COST MATRIX (INR per ton) -------------\n",
    "rate = COST_PER_TON_KM\n",
    "cost_df = dist_df * rate  # multiplying every lane by a constant just scales the objective\n",
    "\n",
    "# ------------- P-MEDIAN WITH FIXED SITES -------------\n",
    "# Variables:\n",
    "#   y_s ∈ {0,1} for all sites (existing fixed to 1; candidates free)\n",
    "#   x_{i,s} ∈ [0,1] assignment of city i to site s\n",
    "model = pulp.LpProblem(\"New_CoPacker_Site_Selection\", pulp.LpMinimize)\n",
    "\n",
    "# y for all sites\n",
    "y = pulp.LpVariable.dicts(\"y\", sites_all, lowBound=0, upBound=1, cat=\"Binary\")\n",
    "# Fix existing plants open\n",
    "for s in EXISTING_PLANTS:\n",
    "    model += y[s] == 1\n",
    "\n",
    "# x assignment\n",
    "x = pulp.LpVariable.dicts(\"x\",\n",
    "                          ((i, s) for i in cities for s in sites_all),\n",
    "                          lowBound=0, upBound=1, cat=\"Continuous\")\n",
    "\n",
    "# Demand coverage: sum_s x_{i,s} = 1\n",
    "for i in cities:\n",
    "    model += pulp.lpSum(x[(i, s)] for s in sites_all) == 1\n",
    "\n",
    "# Linking: x_{i,s} <= y_s\n",
    "for i in cities:\n",
    "    for s in sites_all:\n",
    "        model += x[(i, s)] <= y[s]\n",
    "\n",
    "# Open exactly 5 new sites among candidates\n",
    "model += pulp.lpSum(y[s] for s in candidates) == 5\n",
    "\n",
    "# Objective: min sum_i sum_s demand_i * distance_cost(i,s) * x_{i,s}\n",
    "obj = pulp.lpSum(demand_dict[i] * cost_df.loc[i, s] * x[(i, s)] for i in cities for s in sites_all)\n",
    "model += obj\n",
    "\n",
    "# Solve\n",
    "status = model.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "print(\"Solver status:\", pulp.LpStatus[status])\n",
    "\n",
    "# ------------- RESULTS -------------\n",
    "y_val = {s: int(round(y[s].value())) for s in sites_all}\n",
    "open_sites = [s for s, v in y_val.items() if v == 1]\n",
    "new_sites = [s for s in open_sites if s not in EXISTING_PLANTS]\n",
    "\n",
    "assign = {}\n",
    "for i in cities:\n",
    "    # pick site with largest x value\n",
    "    best_s, best_v = None, -1\n",
    "    for s in sites_all:\n",
    "        v = x[(i, s)].value()\n",
    "        if v is None: v = 0.0\n",
    "        if v > best_v:\n",
    "            best_v, best_s = v, s\n",
    "    assign[i] = best_s\n",
    "\n",
    "# Compute ton-km and INR cost summary\n",
    "flows = []\n",
    "total_ton_km = 0.0\n",
    "total_cost_inr = 0.0\n",
    "for i in cities:\n",
    "    s = assign[i]\n",
    "    d_km = float(dist_df.loc[i, s])\n",
    "    ton = float(demand_dict[i])\n",
    "    ton_km = ton * d_km\n",
    "    cost_inr = ton_km * rate\n",
    "    total_ton_km += ton_km\n",
    "    total_cost_inr += cost_inr\n",
    "    flows.append({\n",
    "        \"city\": i, \"assigned_site\": s, \"distance_km\": round(d_km,1),\n",
    "        \"demand_t\": round(ton,2), \"ton_km\": round(ton_km,1), \"cost_INR\": round(cost_inr,2)\n",
    "    })\n",
    "\n",
    "flows_df = pd.DataFrame(flows).sort_values(\"city\")\n",
    "open_df = pd.DataFrame({\n",
    "    \"site\": open_sites,\n",
    "    \"type\": [\"Existing\" if s in EXISTING_PLANTS else \"New\"]*len(open_sites),\n",
    "    \"lat\": [COORDS[s][0] for s in open_sites],\n",
    "    \"lon\": [COORDS[s][1] for s in open_sites],\n",
    "})\n",
    "\n",
    "print(\"\\nSelected NEW co-packer sites (5):\")\n",
    "for s in new_sites:\n",
    "    print(\" -\", s, f\"@ {COORDS[s]}\")\n",
    "\n",
    "print(\"\\nTotal ton-km:\", round(total_ton_km,1))\n",
    "print(\"Total transport cost (INR):\", f\"{total_cost_inr:,.2f}\")\n",
    "\n",
    "'''\n",
    "# Save Excel\n",
    "out_xlsx = Path(\"new_copacker_site_selection.xlsx\")\n",
    "with pd.ExcelWriter(out_xlsx) as w:\n",
    "    dist_df.round(1).to_excel(w, sheet_name=\"Distance_km\")\n",
    "    cost_df.round(2).to_excel(w, sheet_name=\"Cost_INR_per_ton\")\n",
    "    pd.DataFrame({\"site\": sites_all, \"open_y\": [y_val[s] for s in sites_all],\n",
    "                 \"lat\": [COORDS[s][0] for s in sites_all],\n",
    "                 \"lon\": [COORDS[s][1] for s in sites_all]}).to_excel(w, sheet_name=\"Sites\")\n",
    "    pd.DataFrame({\"new_sites\": new_sites}).to_excel(w, sheet_name=\"Selected_New_Sites\", index=False)\n",
    "    flows_df.to_excel(w, sheet_name=\"City_Assignments\", index=False)\n",
    "\n",
    "print(f\"\\nSaved workbook: {out_xlsx.resolve()}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63dbc49-d784-4bbf-b71f-608d0e95f2e7",
   "metadata": {},
   "source": [
    "## Scenario 3 - Optimized Production Planning for 9 Plants ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec83f2e8-512e-4e6f-a48d-56f56e512f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver status: Optimal\n",
      "Total transport cost (INR): 11,377,862.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WRITAM\\AppData\\Local\\Temp\\ipykernel_30836\\943138981.py:133: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  dem_i = float(dem.loc[dem[\"city\"] == i, \"demand_t\"])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Min-cost production/dispatch plan from 9 plants to 20 demand cities.\n",
    "\n",
    "Inputs\n",
    "------\n",
    "1) Demand CSV: must include 'city' and a demand column (default: 'gifting_tonnes_city').\n",
    "2) Distance Excel: 'city_plant_distances_9x20.xlsx' with sheets:\n",
    "   - 'Road_km' (preferred), OR\n",
    "   - 'Straight_Line_km' (fallback; multiplied by DETOUR_FACTOR).\n",
    "\n",
    "Plants (9)\n",
    "----------\n",
    "Gurgaon, Bhopal, Rajkot, Kolkata, Hyderabad, Mumbai, Bengaluru, Surat, Lucknow\n",
    "(each capacity <= 5,400 t; may produce less).\n",
    "\n",
    "Outputs\n",
    "-------\n",
    "- production_plan_9plants.xlsx (distance, cost, optimal flows, city & plant summaries, total cost)\n",
    "- production_flows_9plants.csv\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pulp\n",
    "\n",
    "# ----------------- FILES (edit paths if needed) -----------------\n",
    "DEMAND_CSV = Path(\"top20_gifting_allocation.csv\")\n",
    "DIST_XLSX  = Path(\"city_plant_distances_9x20.xlsx\")\n",
    "\n",
    "# ----------------- SETTINGS -----------------\n",
    "DEMAND_COL = \"gifting_tonnes_city\"  # change to 'total_demand_tonnes_city' if you want total demand\n",
    "PLANTS_CANON = [\"Gurgaon\",\"Bhopal\",\"Rajkot\",\"Kolkata\",\"Hyderabad\",\"Mumbai\",\"Bengaluru\",\"Surat\",\"Lucknow\"]\n",
    "PLANT_CAPACITY = 5400.0   # t for each plant\n",
    "COST_PER_TON_KM = 4.0     # INR per ton-km (assumption; see comments)\n",
    "REEFER_MULTIPLIER = 1.0   # set 1.3–1.6 for reefer premium if needed\n",
    "USE_ROAD_FIRST = True\n",
    "DETOUR_FACTOR = 1.30      # applied if only straight-line sheet is available\n",
    "\n",
    "# If your distance columns used *_Plant names, we normalize them here:\n",
    "PLANT_RENAME = {\n",
    "    \"Bhopal_Plant\": \"Bhopal\",\n",
    "    \"Kolkata_Plant\": \"Kolkata\",\n",
    "    \"Hyderabad_Plant\": \"Hyderabad\",\n",
    "    \"Mumbai_Plant\": \"Mumbai\",\n",
    "    \"Bengaluru_Plant\": \"Bengaluru\",\n",
    "    \"Surat_Plant\": \"Surat\",\n",
    "    \"Lucknow_Plant\": \"Lucknow\",\n",
    "    \"Gurgaon_Plant\": \"Gurgaon\",\n",
    "    \"Rajkot_Plant\": \"Rajkot\",\n",
    "}\n",
    "# City label normalization to match your distance index\n",
    "CITY_RENAME = {\n",
    "    \"Delhi (NCR)\": \"Delhi NCR\",\n",
    "    \"Mumbai (MMR)\": \"Mumbai\",\n",
    "    \"Pune (PCMC UA)\": \"Pune\",\n",
    "}\n",
    "\n",
    "# ----------------- LOAD DEMAND -----------------\n",
    "dem = pd.read_csv(DEMAND_CSV)\n",
    "dem[\"city\"] = dem[\"city\"].astype(str).str.strip().replace(CITY_RENAME)\n",
    "dem = dem[[\"city\", DEMAND_COL]].rename(columns={DEMAND_COL: \"demand_t\"})\n",
    "dem[\"demand_t\"] = dem[\"demand_t\"].astype(float)\n",
    "\n",
    "# ----------------- LOAD DISTANCES -----------------\n",
    "xl = pd.ExcelFile(DIST_XLSX)\n",
    "sheet = None\n",
    "if USE_ROAD_FIRST and \"Road_km\" in xl.sheet_names:\n",
    "    sheet = \"Road_km\"\n",
    "elif \"Straight_Line_km\" in xl.sheet_names:\n",
    "    sheet = \"Straight_Line_km\"\n",
    "else:\n",
    "    raise FileNotFoundError(\"Distance file must have 'Road_km' or 'Straight_Line_km' sheet.\")\n",
    "\n",
    "dist_df = pd.read_excel(DIST_XLSX, sheet_name=sheet)\n",
    "\n",
    "# If first column is unlabeled index of cities, name it 'city'\n",
    "if dist_df.columns[0].startswith(\"Unnamed\"):\n",
    "    dist_df.rename(columns={dist_df.columns[0]: \"city\"}, inplace=True)\n",
    "# set index to 'city' (or to the first column if needed)\n",
    "if \"city\" in dist_df.columns:\n",
    "    dist_df = dist_df.set_index(\"city\")\n",
    "else:\n",
    "    dist_df = dist_df.set_index(dist_df.columns[0])\n",
    "\n",
    "# Normalize whitespace and rename potential *_Plant columns to canonical names\n",
    "dist_df.index = dist_df.index.astype(str).str.strip()\n",
    "dist_df.rename(columns={k: v for k, v in PLANT_RENAME.items() if k in dist_df.columns}, inplace=True)\n",
    "\n",
    "# Keep only our 9 plants (and order them)\n",
    "missing_plants = [p for p in PLANTS_CANON if p not in dist_df.columns]\n",
    "if missing_plants:\n",
    "    raise ValueError(f\"Plants {missing_plants} not present as columns in '{sheet}'.\")\n",
    "\n",
    "dist_df = dist_df[PLANTS_CANON]\n",
    "\n",
    "# Align rows to the demand cities (and ensure all present)\n",
    "missing_cities = sorted(set(dem[\"city\"]) - set(dist_df.index))\n",
    "if missing_cities:\n",
    "    raise ValueError(f\"Demand cities not found in distance matrix index: {missing_cities}\")\n",
    "dist_df = dist_df.loc[dem[\"city\"]]\n",
    "\n",
    "# If straight-line used while preferring road, apply detour factor to approximate road\n",
    "if sheet == \"Straight_Line_km\" and USE_ROAD_FIRST:\n",
    "    dist_df = dist_df * DETOUR_FACTOR\n",
    "\n",
    "# ----------------- COST MATRIX (INR per ton) -----------------\n",
    "rate = COST_PER_TON_KM * REEFER_MULTIPLIER\n",
    "cost_df = dist_df * rate  # INR per ton for each lane\n",
    "\n",
    "# ----------------- FEASIBILITY -----------------\n",
    "total_demand = dem[\"demand_t\"].sum()\n",
    "total_supply = PLANT_CAPACITY * len(PLANTS_CANON)\n",
    "if total_demand > total_supply + 1e-6:\n",
    "    raise ValueError(f\"Infeasible: total demand {total_demand:,.1f} t > supply {total_supply:,.1f} t\")\n",
    "\n",
    "# ----------------- BUILD & SOLVE LP -----------------\n",
    "cities = list(dem[\"city\"])\n",
    "plants = PLANTS_CANON\n",
    "\n",
    "# Decision variables x[i,j] >= 0 (tonnes)\n",
    "x = pulp.LpVariable.dicts(\"x\", ((i, j) for i in cities for j in plants), lowBound=0, cat=\"Continuous\")\n",
    "\n",
    "model = pulp.LpProblem(\"MinCost_9Plants\", pulp.LpMinimize)\n",
    "\n",
    "# Objective: sum over lanes (tonnes * INR/ton)\n",
    "model += pulp.lpSum(x[(i, j)] * cost_df.loc[i, j] for i in cities for j in plants)\n",
    "\n",
    "# Demand constraints\n",
    "for i in cities:\n",
    "    dem_i = float(dem.loc[dem[\"city\"] == i, \"demand_t\"])\n",
    "    model += pulp.lpSum(x[(i, j)] for j in plants) == dem_i\n",
    "\n",
    "# Plant capacity constraints\n",
    "for j in plants:\n",
    "    model += pulp.lpSum(x[(i, j)] for i in cities) <= PLANT_CAPACITY\n",
    "\n",
    "# Solve (CBC bundled with pulp)\n",
    "status = model.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "print(\"Solver status:\", pulp.LpStatus[status])\n",
    "\n",
    "# ----------------- OUTPUTS -----------------\n",
    "flows = pd.DataFrame(0.0, index=cities, columns=plants)\n",
    "for i in cities:\n",
    "    for j in plants:\n",
    "        val = x[(i, j)].value()\n",
    "        flows.loc[i, j] = 0.0 if val is None else val\n",
    "\n",
    "city_served = flows.sum(axis=1).rename(\"served_t\")\n",
    "plant_output = flows.sum(axis=0).rename(\"plant_production_t\")\n",
    "total_cost_inr = float(pulp.value(model.objective))\n",
    "\n",
    "# Summaries\n",
    "city_summary = pd.concat([dem.set_index(\"city\"), city_served], axis=1)\n",
    "city_summary[\"gap_t\"] = city_summary[\"demand_t\"] - city_summary[\"served_t\"]\n",
    "\n",
    "plant_summary = pd.DataFrame({\n",
    "    \"capacity_t\": PLANT_CAPACITY,\n",
    "    \"produced_t\": plant_output,\n",
    "    \"slack_t\": PLANT_CAPACITY - plant_output,\n",
    "})\n",
    "\n",
    "'''\n",
    "# Save workbook & CSV\n",
    "out_xlsx = Path(\"production_plan_9plants.xlsx\")\n",
    "out_csv  = Path(\"production_flows_9plants.csv\")\n",
    "\n",
    "with pd.ExcelWriter(out_xlsx) as w:\n",
    "    dist_df.round(1).to_excel(w, sheet_name=\"Distance_km\")\n",
    "    cost_df.round(2).to_excel(w, sheet_name=\"Cost_INR_per_ton\")\n",
    "    flows.round(2).to_excel(w, sheet_name=\"Optimal_Flows_tonnes\")       # city x plant\n",
    "    (flows * dist_df).round(1).to_excel(w, sheet_name=\"Ton_km\")         # ton-km on each lane\n",
    "    city_summary.round(2).to_excel(w, sheet_name=\"City_Summary\")\n",
    "    plant_summary.round(2).to_excel(w, sheet_name=\"Plant_Summary\")\n",
    "    pd.DataFrame({\"Total_Cost_INR\": [round(total_cost_inr, 2)]}).to_excel(w, sheet_name=\"Objective\")\n",
    "\n",
    "flows.reset_index().rename(columns={\"index\": \"city\"}).round(2).to_csv(out_csv, index=False)\n",
    "\n",
    "print(f\"Saved workbook: {out_xlsx.resolve()}\")\n",
    "print(f\"Saved flows CSV: {out_csv.resolve()}\")\n",
    "'''\n",
    "print(f\"Total transport cost (INR): {total_cost_inr:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a08fce4-9abc-4535-8269-c818a27734d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6c455-867d-44cc-8d17-80263e8c01ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2dc7e-64ea-4d43-a43f-c9a867ae2413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
